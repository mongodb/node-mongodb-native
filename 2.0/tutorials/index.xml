<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>Tutorials on MongoDB 2.0.0 Driver </title>
      <generator uri="https://hugo.spf13.com">Hugo</generator>
    <link>/node-mongodb-native/2.0/tutorials/index.xml/</link>
    
    
    
    <updated>Mon, 01 Jul 2013 00:00:00 UTC</updated>
    
    <item>
      <title>Connecting To MongoDB</title>
      <link>/node-mongodb-native/2.0/tutorials/connecting/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 UTC</pubDate>
      
      <guid>/node-mongodb-native/2.0/tutorials/connecting/</guid>
      <description>

&lt;h1 id=&#34;toc_0&#34;&gt;Connecting To MongoDB&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;Connecting to MongoDB using the driver is primarily done using the &lt;code&gt;MongoClient.connect&lt;/code&gt; method and a URI. Let&amp;rsquo;s look at how we connect to a couple of different server topologies.&lt;/p&gt;

&lt;h2 id=&#34;toc_1&#34;&gt;Single Server Connection&lt;/h2&gt;

&lt;p&gt;We have a single MongoDB server instance running on the port &lt;em&gt;27017&lt;/em&gt; Let&amp;rsquo;s connect using the driver and &lt;em&gt;MongoClient.connect&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  db.close();
});    
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s break down the &lt;code&gt;URI&lt;/code&gt; string we passed as the first argument to MongoClient.connect.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mongodb://&lt;/code&gt; is the protocol definition&lt;/li&gt;
&lt;li&gt;&lt;code&gt;localhost:27017&lt;/code&gt; is the server we are connecting to&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/myproject&lt;/code&gt; is the database we wish to connect to&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;toc_2&#34;&gt;Replicaset Server Connection&lt;/h2&gt;

&lt;p&gt;We wish to connect to a ReplicaSet consisting of one primary and 1 or more secondaries. To Do this we need to supply the driver with a seedlist of servers and the name of the ReplicaSet we wish to connect to. Let&amp;rsquo;s take a look at a code example.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017,localhost:27018/myproject?replicaSet=foo&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  db.close();
});    
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s break down the &lt;code&gt;URI&lt;/code&gt; string.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mongodb://&lt;/code&gt; is the protocol definition&lt;/li&gt;
&lt;li&gt;&lt;code&gt;localhost:27017,localhost:27018&lt;/code&gt; is the servers we are connecting to to discover the topology of the ReplicaSet.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/myproject&lt;/code&gt; is the database we wish to connect to&lt;/li&gt;
&lt;li&gt;&lt;code&gt;replicaSet=foo&lt;/code&gt; is the name of the ReplicaSet we are connecting to. This ensures we are connecting to the correct Replicaset. &lt;strong&gt;This is a required parameter when using the 2.0 driver&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;toc_3&#34;&gt;Mongos Proxy Connection&lt;/h2&gt;

&lt;p&gt;We wish to connect to a set of &lt;code&gt;mongos&lt;/code&gt; proxies. Just as in the case of connecting to a ReplicaSet we can provide a seed list of &lt;code&gt;mongos&lt;/code&gt; proxies. This allows the driver to perform failover between proxies automatically in case of a proxy process having been shut down. Let&amp;rsquo;s look at an example of code connecting to a set of proxies.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:50000,localhost:50001/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  db.close();
});    
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s break down the &lt;code&gt;URI&lt;/code&gt; string.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mongodb://&lt;/code&gt; is the protocol definition&lt;/li&gt;
&lt;li&gt;&lt;code&gt;localhost:50000,localhost:50001&lt;/code&gt; is the &lt;em&gt;mongos&lt;/em&gt; proxies we are connecting to.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/myproject&lt;/code&gt; is the database we wish to connect to&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;toc_4&#34;&gt;Authentication&lt;/h2&gt;

&lt;h3 id=&#34;toc_5&#34;&gt;Against The Specified Database&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;MongoClient.connect&lt;/code&gt; also allows us to specify authentication credentials as part of the &lt;code&gt;URI&lt;/code&gt;. Let&amp;rsquo;s assume there is a user &lt;em&gt;dave&lt;/em&gt; with the password &lt;em&gt;password&lt;/em&gt; on the database &lt;em&gt;protected&lt;/em&gt;. To correctly authenticate we will do the following.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://dave:password@localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  db.close();
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s break down the &lt;code&gt;URI&lt;/code&gt; string.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mongodb://&lt;/code&gt; is the protocol definition&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dave:password&lt;/code&gt; is the user name and password for the database&lt;/li&gt;
&lt;li&gt;&lt;code&gt;localhost:27017&lt;/code&gt; is the server we are connecting to&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/myproject&lt;/code&gt; is the database we wish to connect to&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;The password and username must be URI encoded to allow for all any possible illegal characters&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;toc_6&#34;&gt;Indirectly Against Another Database&lt;/h3&gt;

&lt;p&gt;In some cases you might have to authenticate against another database than the one you intend to connect to. This is referred to as delegated authentication. Say you wish to connect to the &lt;em&gt;myproject&lt;/em&gt; database but the user is defined in the &lt;em&gt;admin&lt;/em&gt; database. Let&amp;rsquo;s look at how we would accomplish this.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://dave:password@localhost:27017/myproject?authSource=admin&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  db.close();
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s break down the &lt;code&gt;URI&lt;/code&gt; string.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mongodb://&lt;/code&gt; is the protocol definition&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dave:password&lt;/code&gt; is the user name and password for the database&lt;/li&gt;
&lt;li&gt;&lt;code&gt;localhost:27017&lt;/code&gt; is the server we are connecting to&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/myproject&lt;/code&gt; is the database we wish to connect to&lt;/li&gt;
&lt;li&gt;&lt;code&gt;authSource=admin&lt;/code&gt; is the database we wish to authenticate against&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;toc_7&#34;&gt;MongoClient.connect Optional Parameters&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;The driver has many more options for tweaking than what&amp;rsquo;s available through the &lt;code&gt;URI&lt;/code&gt; specification. These can be passed to the driver using an optional parameters object. The top level fields in the options object are.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;db&lt;/code&gt;, Options that affect the Db instance returned by the MongoClient.connect method.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;replSet&lt;/code&gt;, Options that modify the Replicaset topology connection behavior. &lt;strong&gt;This is a required parameter when using the 2.0 driver&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mongos&lt;/code&gt;, Options that modify the Mongos topology connection behavior.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;server&lt;/code&gt;, Options that modify the Server topology connection behavior.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A simple example connecting to a single server setting all returned queries to be raw BSON buffers and adjusting the poolSize to be 10 connections for this connection.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://dave:password@localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, {
    db: {
      raw: true
    }, 
    server: {
      poolSize: 10
    }
  }, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  db.close();
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s look at the individual options for each of the top level fields.&lt;/p&gt;

&lt;h2 id=&#34;toc_8&#34;&gt;Data base level options&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;w&lt;/code&gt;, {Number/String, &amp;gt; -1 || &amp;lsquo;majority&amp;rsquo;} the write concern for the operation where &amp;lt; 1 is no acknowledgment of write and w &amp;gt;= 1 or w = &amp;lsquo;majority&amp;rsquo; acknowledges the write&lt;/li&gt;
&lt;li&gt;&lt;code&gt;wtimeout&lt;/code&gt;, {Number, 0} set the timeout for waiting for write concern to finish (combines with w option)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fsync&lt;/code&gt;, (Boolean, default:false) write waits for fsync before returning&lt;/li&gt;
&lt;li&gt;&lt;code&gt;j&lt;/code&gt;, (Boolean, default:false) write waits for journal sync before returning&lt;/li&gt;
&lt;li&gt;&lt;code&gt;readPreference&lt;/code&gt; {String}, the preferred read preference (ReadPreference.PRIMARY, ReadPreference.PRIMARY_PREFERRED, ReadPreference.SECONDARY, ReadPreference.SECONDARY_PREFERRED, ReadPreference.NEAREST).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;readPreferenceTags&lt;/code&gt; {Object, default:null}, the tags object {&amp;lsquo;loc&amp;rsquo;:&amp;lsquo;ny&amp;rsquo;} used with the readPreference.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;native_parser&lt;/code&gt; {Boolean, default:false}, use c++ bson parser.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;forceServerObjectId&lt;/code&gt; {Boolean, default:false}, force server to create _id fields instead of client.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pkFactory&lt;/code&gt; {Object}, object overriding the basic ObjectID primary key generation.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;serializeFunctions&lt;/code&gt; {Boolean, default:false}, serialize functions.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;raw&lt;/code&gt; {Boolean, default:false}, perform operations using raw bson buffers.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;retryMiliSeconds&lt;/code&gt; {Number, default:5000}, number of milliseconds between retries.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;numberOfRetries&lt;/code&gt; {Number, default:5}, number of retries off connection.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bufferMaxEntries&lt;/code&gt; {Number, default: -1}, sets a cap on how many operations the driver will buffer up before giving up on getting a working connection, default is -1 which is unlimited.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;toc_9&#34;&gt;Individual Server Level Options&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;poolSize&lt;/code&gt;, {Number, default: 5} Number of connections in the connection pool for each server instance, set to 5 as default for legacy reasons.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ssl&lt;/code&gt;, {Boolean, default: false} Number of connections in the connection pool for each server instance, set to 5 as default for legacy reasons.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sslValidate&lt;/code&gt;, {Boolean, default: false} Validate mongod server certificate against ca (needs to have a mongod server with ssl support, 2.4 or higher).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sslCA&lt;/code&gt;, {Buffer[]|string[], default: null} Array of valid certificates either as Buffers or Strings (needs to have a mongod server with ssl support, 2.4 or higher).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sslCert&lt;/code&gt;, {Buffer|string, default: null} String or buffer containing the certificate we wish to present (needs to have a mongod server with ssl support, 2.4 or higher).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sslKey&lt;/code&gt;, {Buffer|string, default: null} String or buffer containing the certificate private key we wish to present (needs to have a mongod server with ssl support, 2.4 or higher).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sslPass&lt;/code&gt;, {Buffer|string, default: null} String or buffer containing the certificate password (needs to have a mongod server with ssl support, 2.4 or higher).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;autoReconnect&lt;/code&gt;, {Boolean, default: true} Reconnect on error.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;socketOptions.noDelay&lt;/code&gt;, {Boolean, default: true} TCP Socket NoDelay option.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;socketOptions.keepAlive&lt;/code&gt;, {Number, default: 0} TCP KeepAlive on the socket with a X ms delay before start.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;socketOptions.connectTimeoutMS&lt;/code&gt;, {Number, default: 0} TCP Connection timeout setting.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;socketOptions.socketTimeoutMS&lt;/code&gt;, {Number, default: 0} TCP Socket timeout setting.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;toc_10&#34;&gt;Replicaset Level Options&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ha&lt;/code&gt; {Boolean, default:true}, turn on high availability.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;haInterval&lt;/code&gt; {Number, default:5000}, time between each replicaset status check.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;replicaSet&lt;/code&gt; {String}, the name of the replicaset to connect to. &lt;strong&gt;This is a required parameter when using the 2.0 driver&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;secondaryAcceptableLatencyMS&lt;/code&gt; {Number, default:15}, sets the range of servers to pick when using NEAREST (lowest ping ms + the latency fence, ex: range of 1 to (1 + 15) ms)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;connectWithNoPrimary&lt;/code&gt; {Boolean, default:false}, Sets if the driver should connect even if no primary is available.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;poolSize&lt;/code&gt;, {Number, default: 5} Number of connections in the connection pool for each server instance, set to 5 as default for legacy reasons.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ssl&lt;/code&gt;, {Boolean, default: false} Number of connections in the connection pool for each server instance, set to 5 as default for legacy reasons.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sslValidate&lt;/code&gt;, {Boolean, default: false} Validate mongod server certificate against ca (needs to have a mongod server with ssl support, 2.4 or higher).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sslCA&lt;/code&gt;, {Buffer[]|string[], default: null} Array of valid certificates either as Buffers or Strings (needs to have a mongod server with ssl support, 2.4 or higher).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sslCert&lt;/code&gt;, {Buffer|string, default: null} String or buffer containing the certificate we wish to present (needs to have a mongod server with ssl support, 2.4 or higher).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sslKey&lt;/code&gt;, {Buffer|string, default: null} String or buffer containing the certificate private key we wish to present (needs to have a mongod server with ssl support, 2.4 or higher).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sslPass&lt;/code&gt;, {Buffer|string, default: null} String or buffer containing the certificate password (needs to have a mongod server with ssl support, 2.4 or higher).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;socketOptions.noDelay&lt;/code&gt;, {Boolean, default: true} TCP Socket NoDelay option.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;socketOptions.keepAlive&lt;/code&gt;, {Number, default: 0} TCP KeepAlive on the socket with a X ms delay before start.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;socketOptions.connectTimeoutMS&lt;/code&gt;, {Number, default: 0} TCP Connection timeout setting.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;socketOptions.socketTimeoutMS&lt;/code&gt;, {Number, default: 0} TCP Socket timeout setting.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;toc_11&#34;&gt;Mongos Proxy Level Options&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ha&lt;/code&gt; {Boolean, default:true}, turn on high availability.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;haInterval&lt;/code&gt; {Number, default:5000}, time between each replicaset status check.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;secondaryAcceptableLatencyMS&lt;/code&gt; {Number, default:15}, sets the range of servers to pick when using NEAREST (lowest ping ms + the latency fence, ex: range of 1 to (1 + 15) ms)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;poolSize&lt;/code&gt;, {Number, default: 5} Number of connections in the connection pool for each server instance, set to 5 as default for legacy reasons.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ssl&lt;/code&gt;, {Boolean, default: false} Number of connections in the connection pool for each server instance, set to 5 as default for legacy reasons.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sslValidate&lt;/code&gt;, {Boolean, default: false} Validate mongod server certificate against ca (needs to have a mongod server with ssl support, 2.4 or higher).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sslCA&lt;/code&gt;, {Buffer[]|string[], default: null} Array of valid certificates either as Buffers or Strings (needs to have a mongod server with ssl support, 2.4 or higher).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sslCert&lt;/code&gt;, {Buffer|string, default: null} String or buffer containing the certificate we wish to present (needs to have a mongod server with ssl support, 2.4 or higher).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sslKey&lt;/code&gt;, {Buffer|string, default: null} String or buffer containing the certificate private key we wish to present (needs to have a mongod server with ssl support, 2.4 or higher).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sslPass&lt;/code&gt;, {Buffer|string, default: null} String or buffer containing the certificate password (needs to have a mongod server with ssl support, 2.4 or higher).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;socketOptions.noDelay&lt;/code&gt;, {Boolean, default: true} TCP Socket NoDelay option.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;socketOptions.keepAlive&lt;/code&gt;, {Number, default: 0} TCP KeepAlive on the socket with a X ms delay before start.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;socketOptions.connectTimeoutMS&lt;/code&gt;, {Number, default: 0} TCP Connection timeout setting.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;socketOptions.socketTimeoutMS&lt;/code&gt;, {Number, default: 0} TCP Socket timeout setting.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Connection Failures</title>
      <link>/node-mongodb-native/2.0/tutorials/connection_failures/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 UTC</pubDate>
      
      <guid>/node-mongodb-native/2.0/tutorials/connection_failures/</guid>
      <description>

&lt;h1 id=&#34;toc_0&#34;&gt;Connection Failures and Retries&lt;/h1&gt;

&lt;p&gt;This comes up a lot because there is some confusion about how the driver works when it comes to Socket timeouts and retries. This Tutorial attempts to clarify the driver&amp;rsquo;s behavior and explains why, for some legacy reasons as well as for some design reasons, the driver works the way it does.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start off by looking at the Simple case of a single server connection and how it behaves when tweaking the options that control the driver behavior on server disconnects.&lt;/p&gt;

&lt;p&gt;First let&amp;rsquo;s start with a simple script performing inserts and find, and running against a server on &lt;code&gt;localhost:27017&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , f = require(&#39;util&#39;).format;

MongoClient.connect(&#39;mongodb://localhost:27017/test&#39;, function(err, db) {
  var col = db.collection(&#39;t&#39;);

  setInterval(function() {
    col.insert({a:1}, function(err, r) {
      console.log(&amp;quot;insert&amp;quot;)
      console.log(err)

      col.findOne({}, function(err, doc) {
        console.log(&amp;quot;findOne&amp;quot;)
        console.log(err)
      });
    })
  }, 1000)
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Start the script and notice how it prints out &lt;code&gt;insert&lt;/code&gt; and &lt;code&gt;findOne&lt;/code&gt; every second. Now shut down the &lt;code&gt;mongod&lt;/code&gt; process and notice how you stop seeing the console printouts. What is happening is that the server is buffering operations until the &lt;code&gt;mongod&lt;/code&gt; returns because the two parameters controlling this behavior are set to the default value. These parameters are:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;code&gt;Parameter&lt;/code&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;&lt;code&gt;Value&lt;/code&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;&lt;code&gt;Description&lt;/code&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;autoReconnect&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;true&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Driver will attempt to auto reconnect&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;bufferMaxEntries&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Max Number of operations buffered while waiting for server reconnect. Driver will error out all operations if the number of buffered operations goes over the limit set&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;By default the driver attempts to reconnect and buffers all operations until it can. This is due to backward compatibility.&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s try to disable the &lt;code&gt;bufferMaxEntries&lt;/code&gt; by setting it to &lt;code&gt;0&lt;/code&gt; and see what happens.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , f = require(&#39;util&#39;).format;

MongoClient.connect(&#39;mongodb://localhost:27017/test&#39;, {
    db: { bufferMaxEntries: 0 }
  }, function(err, db) {
  var col = db.collection(&#39;t&#39;);

  setInterval(function() {
    col.insert({a:1}, function(err, r) {
      console.log(&amp;quot;insert&amp;quot;)
      console.log(err)

      col.findOne({}, function(err, doc) {
        console.log(&amp;quot;findOne&amp;quot;)
        console.log(err)
      });
    })
  }, 1000)
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Start the script running and then shut down the &lt;code&gt;mongod&lt;/code&gt; process. Notice how all operations are now erroring out instead of just being buffered? Now restart the &lt;code&gt;mongod&lt;/code&gt; service and you will see the the operations once again correctly being executed.&lt;/p&gt;

&lt;p&gt;So what happens if we disable &lt;code&gt;autoReconnect&lt;/code&gt; by setting it to &lt;code&gt;false&lt;/code&gt;? Let&amp;rsquo;s take a look.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , f = require(&#39;util&#39;).format;

MongoClient.connect(&#39;mongodb://localhost:27017/test?autoReconnect=false&#39;, function(err, db) {
  var col = db.collection(&#39;t&#39;);

  setInterval(function() {
    col.insert({a:1}, function(err, r) {
      console.log(&amp;quot;insert&amp;quot;)
      console.log(err)

      col.findOne({}, function(err, doc) {
        console.log(&amp;quot;findOne&amp;quot;)
        console.log(err)
      });
    })
  }, 1000)
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When you shut down the &lt;code&gt;mongod&lt;/code&gt; process, the driver stops processing operations and keeps buffering them due to &lt;code&gt;bufferMaxEntries&lt;/code&gt; being &lt;code&gt;-1&lt;/code&gt; by default meaning buffer all operations. When you bring the &lt;code&gt;mongod&lt;/code&gt; process back up you will notice how it does not change the fact that we are buffering. This is a legacy behavior and less than ideal. So you will want to set &lt;code&gt;bufferMaxEntries&lt;/code&gt; to 0 or a low number if you wish to turn off &lt;code&gt;autoReconnect&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;toc_1&#34;&gt;The Matrix of Behavior&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s put all the possible values of &lt;code&gt;autoReconnect&lt;/code&gt; and &lt;code&gt;bufferMaxEntries&lt;/code&gt; in a table so we can more easily understand the behavior.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;code&gt;autoReconnect&lt;/code&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;&lt;code&gt;bufferMaxEntries&lt;/code&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;&lt;code&gt;Description&lt;/code&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;true&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Auto reconnect but do not buffer operations, error out until server reconnect&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;true&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Auto reconnect, buffer all operations until memory run out&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;true&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Auto reconnect, buffer all operations until the bufferMaxEntries is reached and then error out all buffered operations&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;false&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Auto reconnect is off, do not buffer operations, error out all operations&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;false&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Auto reconnect is off, buffer all operations until memory run out&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;false&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&amp;gt; 0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Auto reconnect is off, buffer all operations until the bufferMaxEntries is reached and then error out all buffered operations&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;So why is this the case? Well, the main reason is a combination of the asynchronous behavior of &lt;code&gt;node.js&lt;/code&gt; as well as &lt;code&gt;Replicasets&lt;/code&gt;. When you are using a single server the behavior might be a bit mystifying, but it makes sense in the context of the &lt;code&gt;Replicaset&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Say you have a &lt;code&gt;Replicaset&lt;/code&gt; where a new primary is elected. If the driver does not buffer the operations, it will have to error out all operations until there is a new primary available in the set. This complicates people&amp;rsquo;s code as every operation could potentially fail and thus the driver a long time ago took the decision to make this transparent to the user by buffering operations until the new &lt;code&gt;primary&lt;/code&gt; is available and then replaying them. &lt;code&gt;bufferMaxEntries&lt;/code&gt; was added later to allow developers to control this behavior themselves if they wished to be instantly notified about write errors f.ex instead of letting the driver handle it.&lt;/p&gt;

&lt;h2 id=&#34;toc_2&#34;&gt;The Confusion&lt;/h2&gt;

&lt;p&gt;A lot of the confusion comes from mistaking &lt;code&gt;socketTimeoutMS&lt;/code&gt; with how the async driver works. &lt;code&gt;socketTimeoutMS&lt;/code&gt; only applies to sockets if they have successfully connected to the server, but have not been in use and they reach the &lt;code&gt;socketTimeoutMS&lt;/code&gt;. In contrast, &lt;code&gt;connectionTimeoutMS&lt;/code&gt; applies only to the &lt;em&gt;initial&lt;/em&gt; server connection process timeout.  The &amp;lsquo;connectionTimeoutMS&amp;rsquo; is independent of the &lt;code&gt;socketTimeoutMS&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;However, some people set &lt;code&gt;socketTimeoutMS&lt;/code&gt; expecting it to influence timeouts for operations. But as we have seen above the &lt;code&gt;autoReconnect&lt;/code&gt; and &lt;code&gt;bufferMaxEntries&lt;/code&gt; are the two settings that control that behavior.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s worth noting that you should ensure you have a reasonable &lt;code&gt;socketTimeoutMS&lt;/code&gt;. A lot of people set it way way too low and find themselves with timeouts happening all the time as operations are infrequent enough to cause constant connection closing and reconnect events.&lt;/p&gt;

&lt;p&gt;The rule of thumb I always impart is:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Set &lt;em&gt;socketTimeoutMS&lt;/em&gt; to at least &lt;code&gt;2-3x&lt;/code&gt; the longest running operation in your application or the interval between operations, too ensure you don&amp;rsquo;t timeout long running operations or servers where there are big gaps of time between operations.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;toc_3&#34;&gt;What You are Probably Looking For&lt;/h2&gt;

&lt;p&gt;Most people who start changing &lt;code&gt;socketTimeoutMS&lt;/code&gt; are actually looking for the &lt;code&gt;maxTimeMS&lt;/code&gt; property to limit the time a query runs against the server before it gets aborted. Let&amp;rsquo;s look at how to apply this property on a query.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , f = require(&#39;util&#39;).format;

MongoClient.connect(&#39;mongodb://localhost:27017/test&#39;, function(err, db) {
  var cursor = db.collection(&#39;t&#39;).find({}).maxTimeMS(1000);
  cursor.toArray(function(err, docs) {
    console.dir(docs)
    db.close();
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This executes a query and sets the &lt;code&gt;maxTimeMS&lt;/code&gt; property to &lt;code&gt;1000&lt;/code&gt; milliseconds. If the query runs for longer than that time it will be aborted by the server.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Connection URI</title>
      <link>/node-mongodb-native/2.0/tutorials/urls/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 UTC</pubDate>
      
      <guid>/node-mongodb-native/2.0/tutorials/urls/</guid>
      <description>

&lt;h2 id=&#34;toc_0&#34;&gt;The URL connection format&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;mongodb://[username:password@]host1[:port1][,host2[:port2],...[,hostN[:portN]]][/[database][?options]]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The URL format is unified across official drivers from Mongodb with some options not supported on some drivers due to implementation differences. The ones not supported by the Node.js driver are left out for simplicities sake.&lt;/p&gt;

&lt;h3 id=&#34;toc_1&#34;&gt;Basic parts of the url&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mongodb://&lt;/code&gt; is a required prefix to identify that this is a string in the standard connection format.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;username:password@&lt;/code&gt; is optional. If given, the driver will attempt to login to a database after connecting to a database server.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;host1&lt;/code&gt; is the only required part of the URI. It identifies either a hostname, IP address, or unix domain socket&lt;/li&gt;
&lt;li&gt;&lt;code&gt;:portX&lt;/code&gt; is optional and defaults to :27017 if not provided.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/database&lt;/code&gt; is the name of the database to login to and thus is only relevant if the username:password@ syntax is used. If not specified the &amp;ldquo;admin&amp;rdquo; database will be used by default.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;?options&lt;/code&gt; are connection options. Note that if database is absent there is still a / required between the last host and the ? introducing the options. Options are name=value pairs and the pairs are separated by &amp;ldquo;&amp;amp;&amp;ldquo;. For any unrecognized or unsupported option, a driver should log a warning and continue processing. A driver should not support any options that are not explicitly defined in this specification. This is in order to reduce the likelihood that different drivers will support overlapping that differ in small but incompatible ways (like different name, different values, or different default value).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;toc_2&#34;&gt;Replica set configuration:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;replicaSet=name&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;The driver verifies that the name of the replica set it connects to matches this name. Implies that the hosts given are a seed list, and the driver will attempt to find all members of the set.&lt;/li&gt;
&lt;li&gt;No default value.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;This is a required parameter when using the 2.0 driver&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;toc_3&#34;&gt;Connection Configuration:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;ssl=true|false|prefer&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;true: the driver initiates each connections with SSL&lt;/li&gt;
&lt;li&gt;false: the driver initiates each connection without SSL&lt;/li&gt;
&lt;li&gt;prefer: the driver tries to initiate each connection with SSL, and falls back to without SSL if it fails.&lt;/li&gt;
&lt;li&gt;Default value is false.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;connectTimeoutMS=ms&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;How long a connection can take to be opened before timing out.&lt;/li&gt;
&lt;li&gt;Current driver behavior already differs on this, so the default must be left to each driver. For new implementations, the default should be to never timeout.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;socketTimeoutMS=ms&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;How long a send or receive on a socket can take before timing out.&lt;/li&gt;
&lt;li&gt;Current driver behavior already differs on this, so the default must be left to each driver. For new implementations, the default should be to never timeout.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;toc_4&#34;&gt;Connection pool configuration:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;maxPoolSize=n:&lt;/code&gt; The maximum number of connections in the connection pool

&lt;ul&gt;
&lt;li&gt;Default value is 5&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;toc_5&#34;&gt;Write concern configuration:&lt;/h3&gt;

&lt;p&gt;More detailed information about write concerns can be found at &lt;a href=&#34;http://www.mongodb.org/display/DOCS/getLastError+Command&#34;&gt;http://www.mongodb.org/display/DOCS/getLastError+Command&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;w=wValue&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;For numeric values above 1, the driver adds { w : wValue } to the getLastError command.&lt;/li&gt;
&lt;li&gt;wValue is typically a number, but can be any string in order to allow for specifications like &amp;ldquo;majority&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Default value is 1.

&lt;ul&gt;
&lt;li&gt;wValue == -1 ignore network errors&lt;/li&gt;
&lt;li&gt;wValue == 0 no write acknowledgement&lt;/li&gt;
&lt;li&gt;wValue == 1 perform a write acknowledgement&lt;/li&gt;
&lt;li&gt;wValue == 2 perform a write acknowledgement across primary and one secondary&lt;/li&gt;
&lt;li&gt;wValue == &amp;lsquo;majority&amp;rsquo; perform a write acknowledgement across the majority of servers in the replicaset&lt;/li&gt;
&lt;li&gt;wValue == &amp;lsquo;tag name&amp;rsquo; perform a write acknowledgement against the replicaset tag name&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;wtimeoutMS=ms&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The driver adds { wtimeout : ms } to the getlasterror command.&lt;/li&gt;
&lt;li&gt;Used in combination with w&lt;/li&gt;
&lt;li&gt;No default value&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;journal=true|false&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;true: Sync to journal.&lt;/li&gt;
&lt;li&gt;false: the driver does not add j to the getlasterror command&lt;/li&gt;
&lt;li&gt;Default value is false&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;fsync=true|false&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;true: Sync to disk.&lt;/li&gt;
&lt;li&gt;false: the driver does not add fsync to the getlasterror command&lt;/li&gt;
&lt;li&gt;Default value is false&lt;/li&gt;
&lt;li&gt;If conflicting values for fireAndForget, and any write concern are passed the driver should raise an exception about the conflict.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;toc_6&#34;&gt;Auth options&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;authSource=string:&lt;/code&gt; Used when the user for authentication is stored in another database using indirect authentication.

&lt;ul&gt;
&lt;li&gt;Default value is null&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;toc_7&#34;&gt;Read Preference&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;slaveOk=true|false:&lt;/code&gt; Whether a driver connected to a replica set will send reads to slaves/secondaries.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Default value is false&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;readPreference=enum:&lt;/code&gt; The read preference for this connection. If set, it overrides any slaveOk value.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Enumerated values:

&lt;ul&gt;
&lt;li&gt;primary&lt;/li&gt;
&lt;li&gt;primaryPreferred&lt;/li&gt;
&lt;li&gt;secondary&lt;/li&gt;
&lt;li&gt;secondaryPreferred&lt;/li&gt;
&lt;li&gt;nearest&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Default value is primary&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;readPreferenceTags=string.&lt;/code&gt; A representation of a tag set as a comma-separated list of colon-separated key-value pairs, e.g. &lt;code&gt;dc:ny,rack:1&lt;/code&gt;. Spaces should be stripped from beginning and end of all keys and values. To specify a list of tag sets, using multiple readPreferenceTags, e.g. &lt;code&gt;readPreferenceTags=dc:ny,rack:1&amp;amp;readPreferenceTags=dc:ny&amp;amp;readPreferenceTags=&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Note the empty value, it provides for fallback to any other secondary server if none is available&lt;/li&gt;
&lt;li&gt;Order matters when using multiple readPreferenceTags&lt;/li&gt;
&lt;li&gt;There is no default value&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>CRUD Operations</title>
      <link>/node-mongodb-native/2.0/tutorials/crud_operations/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 UTC</pubDate>
      
      <guid>/node-mongodb-native/2.0/tutorials/crud_operations/</guid>
      <description>

&lt;h1 id=&#34;toc_0&#34;&gt;Driver CRUD Operations&lt;/h1&gt;

&lt;p&gt;The driver crud operations are defined as the operations performed to insert/update/remove and query for documents. In this tutorial we will cover both the basic CRUD methods as well as the specialized &lt;em&gt;findAndModify&lt;/em&gt; based methods and the new Bulk API methods allowing for efficient bulk write operations. But let&amp;rsquo;s start with a simple introduction to the insert, update and remove operations that are on the collection class.&lt;/p&gt;

&lt;h2 id=&#34;toc_1&#34;&gt;Write Methods&lt;/h2&gt;

&lt;h3 id=&#34;toc_2&#34;&gt;Inserting Documents&lt;/h3&gt;

&lt;p&gt;The &lt;em&gt;insertOne&lt;/em&gt; and &lt;em&gt;insertMany&lt;/em&gt; methods exists on the &lt;em&gt;Collection&lt;/em&gt; class and is used to insert documents into MongoDB. Code speaks a thousand words so let&amp;rsquo;s see two simple examples of inserting documents.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  // Insert a single document
  db.collection(&#39;inserts&#39;).insertOne({a:1}, function(err, r) {
    assert.equal(null, err);
    assert.equal(1, r.insertedCount);

    // Insert multiple documents
    db.collection(&#39;inserts&#39;).insertMany([{a:2}, {a:3}], function(err, r) {
      assert.equal(null, err);
      assert.equal(2, r.insertedCount);

      db.close();
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first insert inserts a single document into the &lt;em&gt;inserts&lt;/em&gt; collection. Notice that we are not explicitly creating a new &lt;em&gt;inserts&lt;/em&gt; collection as the server will create it implicitly when we insert the first document. The method &lt;code&gt;Db.createIndex&lt;/code&gt; only really needs to be used when creating non standard collections such as capped collections or where other parameters than the default collections need to be applied.&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;insertOne&lt;/em&gt; and &lt;em&gt;insertMany&lt;/em&gt; methods also accepts an second argument that can be an options object. This object can have the following fields.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;w&lt;/code&gt;, {Number/String, &amp;gt; -1 || &amp;lsquo;majority&amp;rsquo;} the write concern for the operation where &amp;lt; 1 is no acknowledgment of write and w &amp;gt;= 1 or w = &amp;lsquo;majority&amp;rsquo; acknowledges the write.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;wtimeout&lt;/code&gt;, {Number, 0} set the timeout for waiting for write concern to finish (combines with w option).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;j&lt;/code&gt;, (Boolean, default:false) write waits for journal sync.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;serializeFunctions&lt;/code&gt;, (Boolean, default:false) serialize functions on an object to mongodb, by default the driver does not serialize any functions on the passed in documents.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;forceServerObjectId&lt;/code&gt;, (Boolean, default:false) Force server to assign _id values instead of driver.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let&amp;rsquo;s look at a simple example where we are writing to a replicaset and we wish to ensure that we serialize a passed in function as well as have the server assign the &lt;em&gt;_id&lt;/em&gt; for each document.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  // Insert a single document
  db.collection(&#39;inserts&#39;).insertOne({
        a:1
      , b: function() { return &#39;hello&#39;; }
    }, {
        w: &#39;majority&#39;
      , wtimeout: 10000
      , serializeFunctions: true
      , forceServerObjectId: true
    }, function(err, r) {
    assert.equal(null, err);
    assert.equal(1, r.insertedCount);
    db.close();
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That wraps up the &lt;em&gt;insert&lt;/em&gt; methods. Next let&amp;rsquo;s look at the &lt;em&gt;update&lt;/em&gt; methods.&lt;/p&gt;

&lt;h3 id=&#34;toc_3&#34;&gt;Updating Documents&lt;/h3&gt;

&lt;p&gt;The &lt;em&gt;updateOne&lt;/em&gt; and &lt;em&gt;updateMany&lt;/em&gt; methods exists on the &lt;em&gt;Collection&lt;/em&gt; class and is used to update and upsert documents into MongoDB. Let&amp;rsquo;s look at a couple of usage examples.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  var col = db.collection(&#39;updates&#39;);
  // Insert a single document
  col.insertMany([{a:1}, {a:2}, {a:2}], function(err, r) {
    assert.equal(null, err);
    assert.equal(3, r.insertedCount);

    // Update a single document
    col.updateOne({a:1}, {$set: {b: 1}}, function(err, r) {
      assert.equal(null, err);
      assert.equal(1, r.matchedCount);
      assert.equal(1, r.modifiedCount);

      // Update multiple documents
      col.updateMany({a:2}, {$set: {b: 1}}, function(err, r) {
        assert.equal(null, err);
        assert.equal(2, r.matchedCount);
        assert.equal(2, r.modifiedCount);

        // Upsert a single document
        col.updateOne({a:3}, {$set: {b: 1}}, {
          upsert: true
        }, function(err, r) {
          assert.equal(null, err);
          assert.equal(0, r.matchedCount);
          assert.equal(1, r.upsertedCount);
          db.close();
        });
      });
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;em&gt;update&lt;/em&gt; method also accepts an second argument that can be an options object. This object can have the following fields.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;w&lt;/code&gt;, {Number/String, &amp;gt; -1 || &amp;lsquo;majority&amp;rsquo;} the write concern for the operation where &amp;lt; 1 is no acknowledgment of write and w &amp;gt;= 1 or w = &amp;lsquo;majority&amp;rsquo; acknowledges the write.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;wtimeout&lt;/code&gt;, {Number, 0} set the timeout for waiting for write concern to finish (combines with w option).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;j&lt;/code&gt;, (Boolean, default:false) write waits for journal sync.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;multi&lt;/code&gt;, (Boolean, default:false) Update one/all documents with operation.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;upsert&lt;/code&gt;, (Boolean, default:false) Update operation is an upsert.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Just as for &lt;em&gt;insert&lt;/em&gt; the &lt;em&gt;update&lt;/em&gt; method allows you to specify a per operation write concern using the &lt;em&gt;w&lt;/em&gt;, &lt;em&gt;wtimeout&lt;/em&gt; and &lt;em&gt;fsync&lt;/em&gt; parameters&lt;/p&gt;

&lt;h3 id=&#34;toc_4&#34;&gt;Removing Documents&lt;/h3&gt;

&lt;p&gt;The &lt;em&gt;deleteOne&lt;/em&gt; and &lt;em&gt;deleteMany&lt;/em&gt; methods exist on the &lt;em&gt;Collection&lt;/em&gt; class and is used to remove documents from MongoDB. Let&amp;rsquo;s look at a couple of usage examples.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  var col = db.collection(&#39;removes&#39;);
  // Insert a single document
  col.insertMany([{a:1}, {a:2}, {a:2}], function(err, r) {
    assert.equal(null, err);
    assert.equal(3, r.insertedCount);

    // Update a single document
    col.deleteOne({a:1}
      , {$set: {b: 1}}, function(err, r) {
      assert.equal(null, err);
      assert.equal(1, r.deletedCount);

      // Update multiple documents
      col.deleteMany({a:2}
        , {$set: {b: 1}}, function(err, r) {
        assert.equal(null, err);
        assert.equal(2, r.deletedCount);
        db.close();
      });
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;em&gt;removeOne&lt;/em&gt; and &lt;em&gt;deleteMany&lt;/em&gt; methods also accepts an second argument that can be an options object. This object can have the following fields.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;w&lt;/code&gt;, {Number/String, &amp;gt; -1 || &amp;lsquo;majority&amp;rsquo;} the write concern for the operation where &amp;lt; 1 is no acknowledgment of write and w &amp;gt;= 1 or w = &amp;lsquo;majority&amp;rsquo; acknowledges the write.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;wtimeout&lt;/code&gt;, {Number, 0} set the timeout for waiting for write concern to finish (combines with w option).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;j&lt;/code&gt;, (Boolean, default:false) write waits for journal sync.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;single&lt;/code&gt;, (Boolean, default:false) Removes the first document found.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Just as for &lt;em&gt;updateOne/updateMany&lt;/em&gt; and &lt;em&gt;insertOne/insertMany&lt;/em&gt; the &lt;em&gt;deleteOne/deleteMany&lt;/em&gt; method allows you to specify a per operation write concern using the &lt;em&gt;w&lt;/em&gt;, &lt;em&gt;wtimeout&lt;/em&gt; and &lt;em&gt;fsync&lt;/em&gt; parameters&lt;/p&gt;

&lt;h3 id=&#34;toc_5&#34;&gt;FindAndModify and findAndDelete&lt;/h3&gt;

&lt;p&gt;The two methods &lt;em&gt;findOneAndUpdate&lt;/em&gt;, &lt;em&gt;findOneAndDelete&lt;/em&gt; and &lt;em&gt;findOneAndReplace&lt;/em&gt; are special commands that allows the user to update or upsert a document and have the modified or existing document returned. It comes at a cost as the operation takes a write lock for the duration of the operation as it needs to ensure the modification is &lt;em&gt;atomic&lt;/em&gt;. Let&amp;rsquo;s look at &lt;em&gt;findOneAndUpdate&lt;/em&gt; first using an example.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  var col = db.collection(&#39;findAndModify&#39;);
  // Insert a single document
  col.insert([{a:1}, {a:2}, {a:2}], function(err, r) {
    assert.equal(null, err);
    assert.equal(3, r.result.n);

    // Modify and return the modified document
    col.findOneAndUpdate({a:1}, {$set: {b: 1}}, {
        returnOriginal: false
      , sort: [[a,1]]
      , upsert: true
    }, function(err, doc) {
      assert.equal(null, err);
      assert.equal(1, r.value.b);

      // Remove and return a document
      col.findOneAndDelete({a:2}, function(err, r) {
        assert.equal(null, err);
        assert.ok(r.value.b == null);
        db.close();
      });
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;em&gt;findOneAndUpdate&lt;/em&gt; method also accepts an second argument that can be an options object. This object can have the following fields.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;w&lt;/code&gt;, {Number/String, &amp;gt; -1 || &amp;lsquo;majority&amp;rsquo;} the write concern for the operation where &amp;lt; 1 is no acknowledgment of write and w &amp;gt;= 1 or w = &amp;lsquo;majority&amp;rsquo; acknowledges the write.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;wtimeout&lt;/code&gt;, {Number, 0} set the timeout for waiting for write concern to finish (combines with w option).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;j&lt;/code&gt;, (Boolean, default:false) write waits for journal sync.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;upsert&lt;/code&gt;, (Boolean, default:false) Perform an upsert operation.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sort&lt;/code&gt;, (Object, default:null) Sort for find operation.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;projection&lt;/code&gt;, (Object, default:null) Projection for returned result&lt;/li&gt;
&lt;li&gt;&lt;code&gt;returnOriginal&lt;/code&gt;, (Boolean, default:true) Set to false if you want to return the modified object rather than the original. Ignored for remove.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &lt;em&gt;findAndDelete&lt;/em&gt; function is a function especially defined to help remove a document. Let&amp;rsquo;s look at an example of usage.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  var col = db.collection(&#39;findAndModify&#39;);
  // Insert a single document
  col.insert([{a:1}, {a:2}, {a:2}], function(err, r) {
    assert.equal(null, err);
    assert.equal(3, r.result.n);

    // Remove a document from MongoDB and return it
    col.findOneAndRemove({a:1}, {
        sort: [[a,1]]
      }
      , function(err, doc) {
        assert.equal(null, err);
        assert.ok(r.value.b == null);
        db.close();
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Just as for &lt;em&gt;findOneAndUpdate&lt;/em&gt; it allows for an object of options to be passed in that can have the following fields.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;w&lt;/code&gt;, {Number/String, &amp;gt; -1 || &amp;lsquo;majority&amp;rsquo;} the write concern for the operation where &amp;lt; 1 is no acknowledgment of write and w &amp;gt;= 1 or w = &amp;lsquo;majority&amp;rsquo; acknowledges the write.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;wtimeout&lt;/code&gt;, {Number, 0} set the timeout for waiting for write concern to finish (combines with w option).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;j&lt;/code&gt;, (Boolean, default:false) write waits for journal sync.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sort&lt;/code&gt;, (Object, default:null) Sort for find operation.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;toc_6&#34;&gt;BulkWrite&lt;/h3&gt;

&lt;p&gt;The &lt;em&gt;bulkWrite&lt;/em&gt; function allows for a simple set of bulk operations to be done in a non fluent way as in comparison to the bulk API discussed next. Let&amp;rsquo;s look at an example.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  // Get the collection
  var col = db.collection(&#39;bulk_write&#39;);
  col.bulkWrite([
      { insertOne: { document: { a: 1 } } }
    , { updateOne: { filter: {a:2}, update: {$set: {a:2}}, upsert:true } }
    , { updateMany: { filter: {a:2}, update: {$set: {a:2}}, upsert:true } }
    , { deleteOne: { filter: {c:1} } }
    , { deleteMany: { filter: {c:1} } }
    , { replaceOne: { filter: {c:3}, replacement: {c:4}, upsert:true}}]
  , {ordered:true, w:1}, function(err, r) {
    assert.equal(null, err);
    assert.equal(1, r.insertedCount);
    assert.equal(1, Object.keys(r.insertedIds).length);
    assert.equal(1, r.matchedCount);
    assert.equal(0, r.modifiedCount);
    assert.equal(0, r.deletedCount);
    assert.equal(2, r.upsertedCount);
    assert.equal(2, Object.keys(r.upsertedIds).length);

    // Ordered bulk operation
    db.close();
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As we can see the &lt;em&gt;bulkWrite&lt;/em&gt; function takes an array of operation that can be objects of either &lt;em&gt;insertOne&lt;/em&gt;, &lt;em&gt;insertMany&lt;/em&gt;, &lt;em&gt;updateOne&lt;/em&gt;, &lt;em&gt;updateMany&lt;/em&gt;, &lt;em&gt;deleteOne&lt;/em&gt; or &lt;em&gt;deleteMany&lt;/em&gt;. It also takes a second parameter that takes the following options.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ordered&lt;/code&gt;, (Boolean, default:true) Execute in order or out of order.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;w&lt;/code&gt;, {Number/String, &amp;gt; -1 || &amp;lsquo;majority&amp;rsquo;} the write concern for the operation where &amp;lt; 1 is no acknowledgment of write and w &amp;gt;= 1 or w = &amp;lsquo;majority&amp;rsquo; acknowledges the write.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;wtimeout&lt;/code&gt;, {Number, 0} set the timeout for waiting for write concern to finish (combines with w option).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;j&lt;/code&gt;, (Boolean, default:false) write waits for journal sync.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This covers the basic write operations. Let&amp;rsquo;s have a look at the Bulk write operations next.&lt;/p&gt;

&lt;h2 id=&#34;toc_7&#34;&gt;Bulk Write Operations&lt;/h2&gt;

&lt;p&gt;The bulk write operations make it easy to write groups of operations together to MongoDB. There are some caveats and to get the best performance you need to be running against MongoDB &lt;em&gt;2.6&lt;/em&gt; or higher that support the new write commands. Bulk operations are split into &lt;em&gt;ordered&lt;/em&gt; and &lt;em&gt;unordered&lt;/em&gt; bulk operations. An &lt;em&gt;ordered&lt;/em&gt; bulk operation guarantees the order of execution of writes while the &lt;em&gt;unordered&lt;/em&gt; bulk operation makes no assumptions about the order of execution. In the Node.js driver the &lt;em&gt;unordered&lt;/em&gt; bulk operations will group operations according to type and write them in parallel. Let&amp;rsquo;s have a look at how to build an ordered bulk operation.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  var col = db.collection(&#39;bulkops&#39;);
  // Create ordered bulk, for unordered initializeUnorderedBulkOp()
  var bulk = col.initializeOrderedBulkOp();
  // Insert 10 documents
  for(var i = 0; i &amp;lt; 10; i++) {
    bulk.insert({a: i});
  }

  // Next perform some upserts
  for(var i = 0; i &amp;lt; 10; i++) {
    bulk.find({b:i}).upsert().updateOne({b:1});
  }

  // Finally perform a remove operation
  bulk.find({b:1}).deleteOne();

  // Execute the bulk with a journal write concern
  bulk.execute(function(err, result) {
    assert.equal(null, err);
    db.close();
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We will not cover the results object here as it&amp;rsquo;s documented in the driver API. The Bulk API handles all the splitting of operations into multiple writes and also emulates 2.6 and higher write commands for 2.4 and earlier servers.&lt;/p&gt;

&lt;p&gt;There is are some important things to keep in mind when using the bulk API and especially the &lt;em&gt;ordered&lt;/em&gt; bulk API mode. The write commands are single operation type. That means they can only do insert/update and remove. If you f.ex do the following combination of operations.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Insert {a:1}
Update {a:1} to {a:1, b:1}
Insert {a:2}
Remove {b:1}
Insert {a:3}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will result in the driver issuing 4 write commands to the server.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Insert Command with {a:1}
Update Command {a:1} to {a:1, b:1}
Insert Command with {a:2}
Remove Command with {b:1}
Insert Command with {a:3}    
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you instead organize the your &lt;em&gt;ordered&lt;/em&gt; in the following manner.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Insert {a:1}
Insert {a:2}
Insert {a:3}
Update {a:1} to {a:1, b:1}
Remove {b:1}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The number of write commands issued by the driver will be.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Insert Command with {a:1}, {a:2}, {a:3}
Update Command {a:1} to {a:1, b:1}
Remove Command with {b:1}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Allowing for more efficient and faster bulk write operation.&lt;/p&gt;

&lt;p&gt;For &lt;em&gt;unordered&lt;/em&gt; bulk operations this is not important as the driver sorts operations by type and executes them in parallel.&lt;/p&gt;

&lt;p&gt;This covers write operations for MongoDB. Let&amp;rsquo;s look at querying for documents next.&lt;/p&gt;

&lt;h2 id=&#34;toc_8&#34;&gt;Read Methods&lt;/h2&gt;

&lt;p&gt;The main method for querying the database are the &lt;em&gt;find&lt;/em&gt; and the &lt;em&gt;aggregate&lt;/em&gt; method. In this CRUD tutorial we will focus on &lt;em&gt;find&lt;/em&gt; only as &lt;em&gt;aggregate&lt;/em&gt; has it&amp;rsquo;s own &lt;a href=&#34;/tutorials/aggregation&#34;&gt;Aggregation Tutorial&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The &lt;em&gt;method&lt;/em&gt; return a cursor that allows us to operate on the data. The &lt;em&gt;cursor&lt;/em&gt; also implements the Node.js 0.10.x or higher stream interface allowing us to pipe the results to other streams. We will not cover streams here as they are covered in the &lt;a href=&#34;/tutorials/streams&#34;&gt;Streams Tutorial&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s look at a simple find example that materializes all the documents from a query using the toArray but limits the number of returned results to 2 documents.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  var col = db.collection(&#39;find&#39;);
  // Insert a single document
  col.insertMany([{a:1}, {a:1}, {a:1}], function(err, r) {
    assert.equal(null, err);
    assert.equal(3, r.insertedCount);

    // Get first two documents that match the query
    col.find({a:1}).limit(2).toArray(function(err, docs) {
      assert.equal(null, err);
      assert.equal(2, docs.length);
      db.close();
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The cursor returned by the &lt;em&gt;find&lt;/em&gt; method has a lot of methods that allow for chaining of options for a query. Once the query is ready to be executed you can retrieve the documents using the &lt;em&gt;next&lt;/em&gt;, &lt;em&gt;each&lt;/em&gt; and &lt;em&gt;toArray&lt;/em&gt; methods. If the query returns a lot of documents it&amp;rsquo;s preferable to use the &lt;em&gt;next&lt;/em&gt; or &lt;em&gt;each&lt;/em&gt; methods as the &lt;em&gt;toArray&lt;/em&gt; method will materialize all the documents into memory before calling the callback function potentially using a lot of memory if the query returns a lot of documents.&lt;/p&gt;

&lt;p&gt;We won&amp;rsquo;t look at the options we can set on the cursor as they can be viewed in the &lt;a href=&#34;/api-docs&#34;&gt;Cursor API documentation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We already looked at &lt;em&gt;toArray&lt;/em&gt; method above. Let&amp;rsquo;s take a look at the &lt;em&gt;next&lt;/em&gt; method.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  var col = db.collection(&#39;find&#39;);
  // Insert a single document
  col.insertMany([{a:1}, {a:1}, {a:1}], function(err, r) {
    assert.equal(null, err);
    assert.equal(3, r.insertedCount);

    // Get first documents from cursor
    col.find({a:1}).limit(2).next(function(err, doc) {
      assert.equal(null, err);
      assert.ok(doc != null);
      db.close();
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;em&gt;next&lt;/em&gt; method allows the application to read one document at a time using callbacks. Let&amp;rsquo;s look at the &lt;em&gt;each&lt;/em&gt; method next.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  var col = db.collection(&#39;find&#39;);
  // Insert a single document
  col.insertMany([{a:1}, {a:1}, {a:1}], function(err, r) {
    assert.equal(null, err);
    assert.equal(3, r.insertedCount);

    // Get first documents from cursor using each
    col.find({a:1}).limit(2).each(function(err, doc) {
      if(doc) {
        db.close();
        // Got a document, terminate the each
        return false;
      }
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;em&gt;each&lt;/em&gt; method will call the supplied callback until there are no more documents available that satisfy the query. Once the available documents is exhausted it will return &lt;em&gt;null&lt;/em&gt; for the second parameter in the callback. If you wish to terminate the each early you should return false in your &lt;em&gt;each&lt;/em&gt; callback. This will stop the cursor from returning documents.&lt;/p&gt;

&lt;p&gt;This covers the basic crud operations in the Node.js MongoDB driver.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Aggregation</title>
      <link>/node-mongodb-native/2.0/tutorials/aggregation/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 UTC</pubDate>
      
      <guid>/node-mongodb-native/2.0/tutorials/aggregation/</guid>
      <description>

&lt;h1 id=&#34;toc_0&#34;&gt;Using the Aggregation Framework&lt;/h1&gt;

&lt;p&gt;The aggregation framework lets you transform and apply grouping, summations and other operations on the documents before they are returned to the application. It&amp;rsquo;s a very powerful unix pipe like framework. In this tutorial we will explore the &lt;strong&gt;aggregate&lt;/strong&gt; method on the &lt;em&gt;Collection&lt;/em&gt; class and see how it can be used to return a cursor we can iterate over. This cursor also implements the Node.js 0.10.x stream interface which we will not cover in this tutorial. For more information about streams and the Node.js driver please look in the &lt;a href=&#34;/tutorials/streams&#34;&gt;Streams Tutorial&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start with a simple example that returns a cursor to iterate over the results from a simple &lt;em&gt;$match&lt;/em&gt; and &lt;em&gt;$sum&lt;/em&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  var col = db.collection(&#39;aggregate&#39;);
  // Insert a single document
  col.insert([{a:1}, {a:1}, {a:1}], function(err, r) {
    assert.equal(null, err);
    assert.equal(3, r.length);

    // Get first two documents that match the query
    col.aggregate([
          {$match: {}}
        , {$group:
            {_id: &#39;$a&#39;, total: {$sum: &#39;$a&#39;} }
          }
      ]).toArray(function(err, docs) {
      assert.equal(null, err);
      assert.equal(3, docs[0].total);
      db.close();
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When executing the &lt;em&gt;aggregate&lt;/em&gt; method as a cursor it&amp;rsquo;s important to understand that on MongoDB 2.6 or higher this will use the native cursor support for the aggregation framework on the server. If the server is 2.4 or earlier it will emulate the cursor behavior with a virtual cursor. If a callback is included in the &lt;em&gt;aggregate&lt;/em&gt; command it will fall back to the legacy mode that returns the first 16MB of results.&lt;/p&gt;

&lt;p&gt;The cursor returned by the &lt;em&gt;aggregate&lt;/em&gt; command has the same available method as the &lt;em&gt;find&lt;/em&gt; cursor, namely the &lt;em&gt;toArray&lt;/em&gt;, &lt;em&gt;next&lt;/em&gt; and &lt;em&gt;each&lt;/em&gt; methods.&lt;/p&gt;

&lt;p&gt;We already looked at &lt;em&gt;toArray&lt;/em&gt; method above. Let&amp;rsquo;s take a look at the &lt;em&gt;next&lt;/em&gt; method.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  var col = db.collection(&#39;aggregate&#39;);
  // Insert a single document
  col.insert([{a:1}, {a:1}, {a:1}], function(err, r) {
    assert.equal(null, err);
    assert.equal(3, r.length);

    // Get first two documents that match the query
    col.aggregate([
          {$match: {}}
        , {$group:
            {_id: &#39;$a&#39;, total: {$sum: &#39;$a&#39;} }
          }
      ]).next(function(err, doc) {
      assert.equal(null, err);
      assert.equal(3, doc.total);
      db.close();
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;em&gt;next&lt;/em&gt; method allows the application to read one document at a time using callbacks. Let&amp;rsquo;s look at the &lt;em&gt;each&lt;/em&gt; method next.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  var col = db.collection(&#39;aggregate&#39;);
  // Insert a single document
  col.insert([{a:1}, {a:1}, {a:1}], function(err, r) {
    assert.equal(null, err);
    assert.equal(3, r.length);

    // Get first two documents that match the query
    col.aggregate([
          {$match: {}}
        , {$group:
            {_id: &#39;$a&#39;, total: {$sum: &#39;$a&#39;} }
          }
      ]).each(function(err, doc) {
        if(doc) {
          db.close();
          // Got a document, terminate the each
          return false;
        }
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;em&gt;each&lt;/em&gt; method will call the supplied callback until there are no more documents available that satisfy the query. Once the available documents is exhausted it will return &lt;em&gt;null&lt;/em&gt; for the second parameter in the callback. If you wish to terminate the each early you should return false in your &lt;em&gt;each&lt;/em&gt; callback. This will stop the cursor from returning documents.&lt;/p&gt;

&lt;p&gt;This covers the &lt;em&gt;aggregation&lt;/em&gt; support in the Node.js MongoDB driver.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Streams</title>
      <link>/node-mongodb-native/2.0/tutorials/streams/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 UTC</pubDate>
      
      <guid>/node-mongodb-native/2.0/tutorials/streams/</guid>
      <description>

&lt;h1 id=&#34;toc_0&#34;&gt;Streams Support in the Node.js Driver&lt;/h1&gt;

&lt;p&gt;The MongoDB driver has extensive Stream support for cursors as well as for GridFS. In essence the following aspects of the driver supports Node 0.10.x or higher style streams.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;find&lt;/code&gt; The cursor returned from the &lt;em&gt;find&lt;/em&gt; method is a &lt;em&gt;Readable&lt;/em&gt; stream.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;aggregate&lt;/code&gt; The cursor returned from the &lt;em&gt;aggregate&lt;/em&gt; is a &lt;em&gt;Readable&lt;/em&gt; stream.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;parallelCollectionScan&lt;/code&gt; Returns an array of one or more cursors that all are &lt;em&gt;Readable&lt;/em&gt; streams.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GridStore.prototype.stream&lt;/code&gt; Returns a stream that implements &lt;em&gt;Duplex&lt;/em&gt; allowing for writing data in &lt;em&gt;w&lt;/em&gt; mode and reading data in &lt;em&gt;r&lt;/em&gt; mode.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We will look at a simple example for supported stream starting with the &lt;em&gt;find&lt;/em&gt; command.&lt;/p&gt;

&lt;h2 id=&#34;toc_1&#34;&gt;Find Cursor as a Stream&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s examine a simple query using &lt;em&gt;find&lt;/em&gt; and how to use it as a node.js stream.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  var col = db.collection(&#39;streams&#39;);
  // Insert a single document
  col.insert([{a:1}, {a:1}, {a:1}], function(err, r) {
    assert.equal(null, err);
    assert.equal(3, r.result.n);

    // Get the results using a find stream
    var cursor = col.find({});
    cursor.on(&#39;data&#39;, function(doc) {
      console.dir(doc);
    });

    cursor.once(&#39;end&#39;, function() {
      db.close();
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A very simple and straight forward stream of documents. For each document the cursor will emit the &lt;em&gt;data&lt;/em&gt; event and when the cursor has been exhausted it will issue the &lt;em&gt;end&lt;/em&gt; event. To transform the data you can pipe the data from this stream into another stream. We will not show that here but there are a wide variety of stream based libraries available on &lt;a href=&#34;http://npmjs.org&#34;&gt;NPM&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The stream is in object mode meaning it will emit the actual document instances. If you for some reason need this to be a different output you can use the &lt;code&gt;stream&lt;/code&gt; function on the cursor to supply a transformation method that will be called for each document before it&amp;rsquo;s emitted. Let&amp;rsquo;s take a look at a simple example that uses &lt;em&gt;JSON.stringify&lt;/em&gt; to convert each document to it&amp;rsquo;s JSON string representation.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  var col = db.collection(&#39;streams&#39;);
  // Insert a single document
  col.insert([{a:1}, {a:1}, {a:1}], function(err, r) {
    assert.equal(null, err);
    assert.equal(3, r.result.n);

    // Get the results using a find stream
    var cursor = col.find({}).stream({
      transform: function(doc) { 
        return JSON.stringify(doc);
      }
    });

    cursor.on(&#39;data&#39;, function(doc) {
      console.log(doc);
    });

    cursor.once(&#39;end&#39;, function() {
      db.close();
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That wraps up the behaviors of the &lt;em&gt;Readable&lt;/em&gt; stream for the &lt;em&gt;find&lt;/em&gt; method. Next let&amp;rsquo;s look at the aggregate command.&lt;/p&gt;

&lt;h2 id=&#34;toc_2&#34;&gt;Aggregation Cursor as a Stream&lt;/h2&gt;

&lt;p&gt;The aggregation cursor behaves very much like the &lt;em&gt;find&lt;/em&gt; cursor. It&amp;rsquo;s main difference is that it does not support a &lt;em&gt;transform&lt;/em&gt; method. Let&amp;rsquo;s have a look at a simple example.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  var col = db.collection(&#39;streams&#39;);
  // Insert a single document
  col.insert([{a:1}, {a:1}, {a:1}], function(err, r) {
    assert.equal(null, err);
    assert.equal(3, r.result.n);

    // Get the results using a find stream
    var cursor = col.aggregate([${match: {}}]);
    cursor.on(&#39;data&#39;, function(doc) {
      console.log(doc);
    });

    cursor.once(&#39;end&#39;, function() {
      db.close();
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As one can see the cursor behaves in the exact same way as the cursor that is returned when invoking the &lt;em&gt;find&lt;/em&gt; method. Let&amp;rsquo;s have a look at the &lt;em&gt;parallelCollectionScan&lt;/em&gt; method that is a bit of a special case as it returns one or more cursors.&lt;/p&gt;

&lt;h2 id=&#34;toc_3&#34;&gt;The parallelCollectionScan method&lt;/h2&gt;

&lt;p&gt;The &lt;em&gt;parallelCollectionScan&lt;/em&gt; method is a specialized method that allows for parallel reading of a collection using multiple cursors. This method is only available when connecting to a single server or replicaset topology. Let&amp;rsquo;s look at an example.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  var docs = [];
  // Insert some documents
  for(var i = 0; i &amp;lt; 1000; i++) docs.push({a:i});
  // Get the collection
  var col = db.collection(&#39;parallelCollectionScan&#39;);
  // Insert 1000 documents in a batch
  coll.insert(docs, function(err, result) {
    var results = [];
    // Execute parallelCollectionScan command
    col.parallelCollectionScan({
      numCursors:3
    }, function(err, cursors) {
      assert.equal(null, err);
      assert.ok(cursors != null);
      assert.ok(cursors.length &amp;gt; 0);

      for(var i = 0; i &amp;lt; cursors.length; i++) {
        // Documents from the cursor
        cursors[i].on(&#39;data&#39;, function(doc) {
          results.push(doc);
        });

        // The end signal for each cursor
        cursors[i].once(&#39;end&#39;, function() {
          numCursors = numCursors - 1;
          // No more cursors let&#39;s ensure we got all results
          if(numCursors == 0) {
            assert.equal(docs.length, results.length);
            db.close();
          }
        });
      }
    });
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this example we use each cursor as a stream and when all cursors have emitted the &lt;em&gt;end&lt;/em&gt; event we check that the number of inserted documents match the number of emitted documents. Each cursor returned from the &lt;em&gt;parallelCollectionScan&lt;/em&gt; method is functionally equivalent to the cursors returned from the the &lt;em&gt;find&lt;/em&gt; method.&lt;/p&gt;

&lt;h1 id=&#34;toc_4&#34;&gt;GridStore the Read/Write Stream&lt;/h1&gt;

&lt;p&gt;Until now all the methods we have covered are &lt;em&gt;Readable&lt;/em&gt; meaning they can only provide a readable stream. GridStore implements the &lt;em&gt;Duplex&lt;/em&gt; stream meaning it can not only be read as a Stream (say stream a mp3 straight from your GridFS collections) but also be written to (say upload a file directly via http into GridFS). Let&amp;rsquo;s look at the simple example of streaming a GridStore file and then one where we use an incoming stream to write to GridFS.&lt;/p&gt;

&lt;h2 id=&#34;toc_5&#34;&gt;Streaming a GridFS file to disk&lt;/h2&gt;

&lt;p&gt;Streaming a GridStore file to disk is fairly simple. The example below reads in a pdf file and saves it in GridFS. It then creates a GridStore instance pointing to the newly saved pdf file and passes the stream to a file write stream using pipe.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , GridStore = require(&#39;mongodb&#39;).GridStore
  , fs = require(&#39;fs&#39;)
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  // Set up gridStore
  var gs = new GridStore(db, &#39;simple_100_document_toArray.png&#39;, &#39;w&#39;);
  var filename = &#39;./simple_100_document_toArray.png&#39;;
  var outputFilename = &#39;./simple_100_document_toArray_out.png&#39;;

  // Write the a file to it (put your own here)
  gs.writeFile(filename, function(err, result) {   
    // Open a readable gridStore
    gs = new GridStore(db, &#39;simple_100_document_toArray.png&#39;, &#39;r&#39;);
    
    // Create a file write stream
    var fileStream = fs.createWriteStream(outputFilename);
    fileStream.on(&#39;close&#39;, function(err) {     
      // Read the temp file and compare
      var compareData = fs.readFileSync(outputFilename);
      var originalData = fs.readFileSync(filename);
      // Validate that the data is the same
      assert.deepEqual(originalData, compareData);      
      db.close();
    })
    
    // Pipe out the data to disk
    var pipeResult = gs.stream().pipe(fileStream);
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;toc_6&#34;&gt;Streaming a File into GridFS&lt;/h2&gt;

&lt;p&gt;In the case of writing a file to GridFS using streams we do the reverse piping the file read stream into a our gridstore instance.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , GridStore = require(&#39;mongodb&#39;).GridStore
  , ObjectID = require(&#39;mongoddb&#39;).ObjectID
  , fs = require(&#39;fs&#39;)
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  
  // Set up gridStore
  var stream = new GridStore(db, &#39;simple_100_document_toArray.png&#39;, &#39;w&#39;).stream();
  // File we want to write to GridFS
  var filename = &#39;./simple_100_document_toArray.png&#39;;  
  // Create a file reader stream to an object
  var fileStream = fs.createReadStream(filename);

  // Finish up once the file has been all read
  stream.on(&amp;quot;end&amp;quot;, function(err) {

    // Just read the content and compare to the raw binary
    GridStore.read(db, &#39;simple_100_document_toArray.png&#39;, function(err, gridData) {
      assert.equal(null, err);
      var fileData = fs.readFileSync(filename);
      assert.equal(fileData.toString(&#39;hex&#39;), gridData.toString(&#39;hex&#39;));
      db.close();
    })
  });

  // Pipe it through to the gridStore
  fileStream.pipe(stream);
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This concludes the support for Node.js 0.10.x streams in the MongoDB driver.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GridFS</title>
      <link>/node-mongodb-native/2.0/tutorials/gridfs/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 UTC</pubDate>
      
      <guid>/node-mongodb-native/2.0/tutorials/gridfs/</guid>
      <description>

&lt;h1 id=&#34;toc_0&#34;&gt;GridFS Support&lt;/h1&gt;

&lt;p&gt;GridFS is a scalable MongoDB &lt;em&gt;filesystem&lt;/em&gt; for storing and retrieving large files. The default limit for a MongoDB record is 16MB, so to store data that is larger than this limit, GridFS can be used. GridFS shards the data into smaller chunks automatically.  See &lt;a href=&#34;http://www.mongodb.org/display/DOCS/GridFS+Specification&#34;&gt;MongoDB documentation&lt;/a&gt; for details.&lt;/p&gt;

&lt;p&gt;GridStore is a single file inside GridFS that can be managed by the script.&lt;/p&gt;

&lt;h2 id=&#34;toc_1&#34;&gt;Open a GridFS file&lt;/h2&gt;

&lt;p&gt;Opening a GridStore (a single file in GridFS) is a bit similar to opening a database. At first you need to create a GridStore object and then &lt;code&gt;open&lt;/code&gt; it.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var gs = new GridStore(db, filename, mode[, options])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Where&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;db&lt;/code&gt; is the database object&lt;/li&gt;
&lt;li&gt;&lt;code&gt;filename&lt;/code&gt; is the name of the file in GridFS that needs to be accessed/created&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mode&lt;/code&gt; indicated the operation, can be one of:

&lt;ul&gt;
&lt;li&gt;&amp;ldquo;r&amp;rdquo; (Read): Looks for the file information in fs.files collection, or creates a new id for this object.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;w&amp;rdquo; (Write): Erases all chunks if the file already exist.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;options&lt;/code&gt; can be used to specify some metadata for the file, for example &lt;code&gt;content_type&lt;/code&gt;, &lt;code&gt;metadata&lt;/code&gt; and &lt;code&gt;chunk_size&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var gs = new GridStore(db, &amp;quot;test.png&amp;quot;, &amp;quot;w&amp;quot;, {
  &amp;quot;content_type&amp;quot;: &amp;quot;image/png&amp;quot;,
  &amp;quot;metadata&amp;quot;:{
      &amp;quot;author&amp;quot;: &amp;quot;Daniel&amp;quot;
  },
  &amp;quot;chunk_size&amp;quot;: 1024*4
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After a GridStore object is created, it needs to be opened.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;gs.open(function(err, gs) {
  // gs is the intialized GridStore object
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Opened GridStore objects have a set of useful exposed properties&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;gs.length&lt;/code&gt; - length of the file in bytes&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gs.contentType&lt;/code&gt; - the content type for the file&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gs.uploadDate&lt;/code&gt; - when the file was uploaded&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gs.metadata&lt;/code&gt; - metadata that was saved with the file&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gs.chunkSize&lt;/code&gt; - chunk size&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Example&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;gs.open(function(err, gs){
  console.log(&amp;quot;this file was uploaded at &amp;quot;+gs.uploadDate);
});
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;toc_2&#34;&gt;Writing to GridFS&lt;/h2&gt;

&lt;p&gt;Writing can be done with &lt;code&gt;write&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;gs.write(data, callback)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where &lt;code&gt;data&lt;/code&gt; is a &lt;code&gt;Buffer&lt;/code&gt; or a string, callback gets two parameters - an error object (if error occured) and result value which indicates if the write was successful or not.&lt;/p&gt;

&lt;p&gt;While the GridStore is not closed, every write is appended to the opened GridStore.&lt;/p&gt;

&lt;h2 id=&#34;toc_3&#34;&gt;Writing a file to GridFS&lt;/h2&gt;

&lt;p&gt;This function opens the GridStore, streams the contents of the file into GridStore, and closes the GridStore.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;gs.writeFile( file, callback )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;file&lt;/code&gt; is a file descriptor, or a string file path&lt;/li&gt;
&lt;li&gt;&lt;code&gt;callback&lt;/code&gt; is a function with two parameters - error object (if error occured) and the GridStore object.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;toc_4&#34;&gt;Reading from a GridFS file&lt;/h2&gt;

&lt;p&gt;Reading from GridStore can be done with &lt;code&gt;read&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;gs.read([size], callback)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;size&lt;/code&gt; is the length of the data to be read&lt;/li&gt;
&lt;li&gt;&lt;code&gt;callback&lt;/code&gt; is a callback function with two parameters - error object (if an error occured) and data (binary string)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;toc_5&#34;&gt;Streaming from GridFS&lt;/h2&gt;

&lt;p&gt;You can stream data as it comes from the database using &lt;code&gt;stream&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;gs.stream([autoclose=false])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;autoclose&lt;/code&gt; If true current GridStore will be closed when EOF and &amp;lsquo;close&amp;rsquo; event will be fired&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The function returns &lt;a href=&#34;http://nodejs.org/docs/v0.4.12/api/streams.html#readable_Stream&#34;&gt;read stream&lt;/a&gt; based on this GridStore file. It supports the events &amp;lsquo;read&amp;rsquo;, &amp;lsquo;error&amp;rsquo;, &amp;lsquo;close&amp;rsquo; and &amp;lsquo;end&amp;rsquo;.&lt;/p&gt;

&lt;h2 id=&#34;toc_6&#34;&gt;Delete a GridFS file&lt;/h2&gt;

&lt;p&gt;GridStore files can be unlinked with &lt;code&gt;unlink&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;GridStore.unlink(db, name, callback)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Where&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;db&lt;/code&gt; is the database object&lt;/li&gt;
&lt;li&gt;&lt;code&gt;name&lt;/code&gt; is either the name of a GridStore object or an array of GridStore object names&lt;/li&gt;
&lt;li&gt;&lt;code&gt;callback&lt;/code&gt; is the callback function&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;toc_7&#34;&gt;Closing a GridFS file&lt;/h2&gt;

&lt;p&gt;GridStore needs to be closed after usage. This can be done with &lt;code&gt;close&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;gs.close(callback)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;toc_8&#34;&gt;Check if a GridFS file exists&lt;/h2&gt;

&lt;p&gt;Checking if a file exists in GridFS can be done with &lt;code&gt;exist&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;GridStore.exist(db, filename, callback)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Where&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;db&lt;/code&gt; is the database object&lt;/li&gt;
&lt;li&gt;&lt;code&gt;filename&lt;/code&gt; is the name of the file to be checked or a regular expression&lt;/li&gt;
&lt;li&gt;&lt;code&gt;callback&lt;/code&gt; is a callback function with two parameters - an error object (if an error occured) and a boolean value indicating if the file exists or not&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;toc_9&#34;&gt;Seek to a Specific position for Reading&lt;/h2&gt;

&lt;p&gt;Seeking can be done with &lt;code&gt;seek&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;gs.seek(position);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This function moves the internal pointer to the specified position.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Logging</title>
      <link>/node-mongodb-native/2.0/tutorials/logging/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 UTC</pubDate>
      
      <guid>/node-mongodb-native/2.0/tutorials/logging/</guid>
      <description>

&lt;h1 id=&#34;toc_0&#34;&gt;Logging&lt;/h1&gt;

&lt;p&gt;The driver lets you log at 3 different levels. These are &lt;code&gt;debug&lt;/code&gt;, &lt;code&gt;info&lt;/code&gt; and &lt;code&gt;error&lt;/code&gt;. By default the log level is at &lt;code&gt;error&lt;/code&gt;. You can change the level, only allow specific classes to log and provide your own logger implementation. Let&amp;rsquo;s look at how we control the log level.&lt;/p&gt;

&lt;h2 id=&#34;toc_1&#34;&gt;Setting Log level&lt;/h2&gt;

&lt;p&gt;Setting the log level is pretty easy. Let&amp;rsquo;s look at example of adjusting it for our application only logging the Db class.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , Logger = require(&#39;mongodb&#39;).Logger
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  // Set debug level
  Logger.setLevel(&#39;debug&#39;);

  // Insert a single document
  db.command({ismaster:true}, function(err, d) {
    assert.equal(null, err);
    db.close();
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Setting the level is as easy as calling the method &lt;code&gt;setLevel&lt;/code&gt; with the string value &lt;code&gt;debug&lt;/code&gt;, &lt;code&gt;info&lt;/code&gt; or &lt;code&gt;error&lt;/code&gt;. Log level is set globally.&lt;/p&gt;

&lt;h2 id=&#34;toc_2&#34;&gt;Filtering On specific classes&lt;/h2&gt;

&lt;p&gt;Say you are only interested in logging a specific class. You can tell the Logger to only log specific class names. Let&amp;rsquo;s take an example Where we only log the &lt;code&gt;Db&lt;/code&gt; class.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , Logger = require(&#39;mongodb&#39;).Logger
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  // Set debug level
  Logger.setLevel(&#39;debug&#39;);
  Logger.filter(&#39;class&#39;, [&#39;Db&#39;]);

  // Insert a single document
  db.command({ismaster:true}, function(err, d) {
    assert.equal(null, err);
    db.close();
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will only log statements on the &lt;code&gt;Db&lt;/code&gt; class. The available classes in the driver are.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Db&lt;/code&gt;: The Db instance log statements&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Server&lt;/code&gt;: A server instance (either standalone, a mongos or replicaset member)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ReplSet&lt;/code&gt;: Replicaset related log statements&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Mongos&lt;/code&gt;: Mongos related log statements&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Cursor&lt;/code&gt;: Cursor log statements&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Pool&lt;/code&gt;: Connection Pool specific log statements&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Connection&lt;/code&gt;: Singular connection specific log statements&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Ping&lt;/code&gt;: Replicaset ping inquiry log statements&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can add your own classes to the logger if you wish by creating your own logger instances. Let&amp;rsquo;s look at a simple example on how to add our custom class to the Logger.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var Logger = require(&#39;mongodb&#39;).Logger
  , assert = require(&#39;assert&#39;);

var A = function() {
  var logger = Logger(&#39;A&#39;, options);

  this.do = function() {
    if(logger.isInfo()) logger.info(&#39;logging A&#39;, {});
  }
}

// Execute A
var a = new A();
a.do();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Pretty simple and straightforward.&lt;/p&gt;

&lt;h2 id=&#34;toc_3&#34;&gt;Custom logger&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s say you don&amp;rsquo;t want the log statements to go to &lt;code&gt;console.log&lt;/code&gt; but want to send them to a new location or maybe transform them before you send them on. Let&amp;rsquo;s define our custom logger.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;var MongoClient = require(&#39;mongodb&#39;).MongoClient
  , Logger = require(&#39;mongodb&#39;).Logger
  , assert = require(&#39;assert&#39;);

// Connection URL
var url = &#39;mongodb://localhost:27017/myproject&#39;;
// Use connect method to connect to the Server
MongoClient.connect(url, function(err, db) {
  assert.equal(null, err);
  console.log(&amp;quot;Connected correctly to server&amp;quot;);

  // Set debug level
  Logger.setLevel(&#39;debug&#39;);
  
  // Set our own logger
  Logger.setCurrentLogger(function(msg, context) {
    console.log(msg, context);
  });

  // Insert a single document
  db.command({ismaster:true}, function(err, d) {
    assert.equal(null, err);
    db.close();
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That wraps up the Logging support in the driver.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ObjectId</title>
      <link>/node-mongodb-native/2.0/tutorials/objectid/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 UTC</pubDate>
      
      <guid>/node-mongodb-native/2.0/tutorials/objectid/</guid>
      <description>

&lt;h1 id=&#34;toc_0&#34;&gt;ObjectId&lt;/h1&gt;

&lt;p&gt;The ObjectId class is the default primary key for a MongoDB document and is usually found in the &lt;code&gt;_id&lt;/code&gt; field in an inserted document. Let&amp;rsquo;s look at an example.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;_id&amp;quot;: ObjectId(&amp;quot;54759eb3c090d83494e2d804&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;An ObjectId is a 12 byte binary BSON type that contain any 12 bytes you want. To be helpful in generating ObjectIds MongoDB drivers and the server will generate them using a default Algorithm. A ObjectId&amp;rsquo;s 12 bytes will be then contain the following.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Size&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;4 bytes&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;a 4-byte value representing the seconds since the Unix epoch&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;3 bytes&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;a 3-byte machine identifier&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2 bytes&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2-byte process id&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;3 bytes&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;3-byte counter, starting with a random value&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In the driver you can tap into this by simply creating a new ObjectId. Let&amp;rsquo;s look at an example that will create an ObjectId that contains a 12 byte description that matches this specification.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var ObjectId = require(&#39;mongodb&#39;).ObjectID
var id = new ObjectId();
console.log(id)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will print a hexadecimal representation of the 12 byte ObjectId the driver generated.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s equally valid to just pass it a 12 byte string (buffer is not currently supported but will be sometime soon). Let&amp;rsquo;s create our own definition of a 12 byte ObjectId.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var ObjectId = require(&#39;mongodb&#39;).ObjectID
var id = new ObjectId(&amp;quot;aaaaaaaaaaaa&amp;quot;);
console.log(id)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will print the hexadecimal value &lt;code&gt;616161616161616161616161&lt;/code&gt; which corresponds to the string &lt;code&gt;aaaaaaaaaaaa&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;toc_1&#34;&gt;Properties of a Generated ObjectId&lt;/h2&gt;

&lt;p&gt;One of the main reasons ObjectId&amp;rsquo;s are generated in the fashion mentioned above by the drivers is that is contains a useful behavior due to the way sorting works. Given that it contains a 4 byte timestamp (resolution of seconds) and an incrementing counter as well as some more unique identifiers such as the machine id once can use the &lt;code&gt;_id&lt;/code&gt; field to sort documents in the order of creation just by simply sorting on the &lt;code&gt;_id&lt;/code&gt; field. This can be useful to save the space needed by an additional timestamp if you wish to track the time of creation of a document.&lt;/p&gt;

&lt;h2 id=&#34;toc_2&#34;&gt;Driver ObjectId Constructor methods&lt;/h2&gt;

&lt;p&gt;The driver allows you to create ObjectId&amp;rsquo;s in a couple of ways as well as allowing you to introspects aspects of the ObjectId.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s look at the actual constructor options. The constructor lets you pass in a 12 byte string or a 24 byte hexadecimal representation as well as no arguments.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var ObjectId = require(&#39;mongodb&#39;).ObjectID
var id = new ObjectId();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Creates a new generated ObjectId using the algorithm outlined above.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var ObjectId = require(&#39;mongodb&#39;).ObjectID
var id = new ObjectId(&amp;quot;aaaaaaaaaaaa&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Creates a new specific ObjectId using the 12 byte string.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var ObjectId = require(&#39;mongodb&#39;).ObjectID
var id = new ObjectId(&amp;quot;616161616161616161616161&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Creates a new specific ObjectId using the 24 byte hexadecimal 12 byte string representation. This is useful for when you are passing back Id&amp;rsquo;s from a web application.&lt;/p&gt;

&lt;h2 id=&#34;toc_3&#34;&gt;Driver ObjectId Static methods&lt;/h2&gt;

&lt;p&gt;The ObjectId static methods are meant to be helpful in making it more explicit what your intention is when creating a new ObjectId.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var ObjectId = require(&#39;mongodb&#39;).ObjectID
var id = ObjectId.createPk();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Creates a new ObjectId instance with a generated key using the algorithm outlined above.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var ObjectId = require(&#39;mongodb&#39;).ObjectID
var id = ObjectId.createFromTime(5000);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Creates an ObjectId from a seconds timestamp with the rest of the bytes in the ObjectId zeroed out.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var ObjectId = require(&#39;mongodb&#39;).ObjectID
var id = ObjectId.createFromHexString(&amp;quot;616161616161616161616161&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Creates and ObjectId from the 24 byte hexadecimal representation of a 12 byte string.&lt;/p&gt;

&lt;h2 id=&#34;toc_4&#34;&gt;Driver ObjectId Instance methods&lt;/h2&gt;

&lt;p&gt;The more interesting methods on an ObjectId instance are the following.&lt;/p&gt;

&lt;h3 id=&#34;toc_5&#34;&gt;getTimestamp()&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var ObjectId = require(&#39;mongodb&#39;).ObjectID
var id = new ObjectId();
console.log(id.getTimestamp())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This method returns a Date object representing the timestamp part of the 12 byte ObjectId as defined by the algorithm above. If the ObjectId is generated by the algorithm you will get the creation time Date object back. However if it&amp;rsquo;s just a random 12 byte sequence obviously the date coming back might be nonsensical.&lt;/p&gt;

&lt;h3 id=&#34;toc_6&#34;&gt;toHexString()&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var ObjectId = require(&#39;mongodb&#39;).ObjectID
var id = new ObjectId(&amp;quot;aaaaaaaaaaaa&amp;quot;);
console.log(id.toHexString())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will print out the hexadecimal representation of the ObjectId.&lt;/p&gt;

&lt;h2 id=&#34;toc_7&#34;&gt;On Buffers&lt;/h2&gt;

&lt;p&gt;Until the ObjectId natively accepts a buffer the best way to transform a Buffer into a valid ObjectId is to do the following.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var ObjectId = require(&#39;mongodb&#39;).ObjectID
var id = new ObjectId(new Buffer(&amp;quot;aaaaaaaaaaaa&amp;quot;).toString());
console.log(id.toHexString())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By converting the buffer into it&amp;rsquo;s string representation we can correctly create a new ObjectId.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tracing</title>
      <link>/node-mongodb-native/2.0/tutorials/tracing/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 UTC</pubDate>
      
      <guid>/node-mongodb-native/2.0/tutorials/tracing/</guid>
      <description>

&lt;h1 id=&#34;toc_0&#34;&gt;Tracing or Prototype Overriding&lt;/h1&gt;

&lt;p&gt;Tracing comes up a couple of times a year so it might be a useful thing for more people than just New Relic or other application metrics companies out there. Maybe you want to instrument the driver to keep some measurements client side on the time it takes for an operation to finish or maybe you want to log all operations somewhere for auditing purposes or maybe you have some awesome new idea about how to do something radically different. Well the good thing is that JavaScript is on your side when it comes to reaching your goals. The rescue comes in the form of the &lt;code&gt;prototype&lt;/code&gt; of the driver classes. Since code speaks a thousand words let&amp;rsquo;s just throw out code where override the &lt;code&gt;findOne&lt;/code&gt; method to print the time it took for the operation to the console.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;var Collection = require(&#39;mongodb&#39;).Collection
  , MongoClient = require(&#39;mongodb&#39;).MongoClient
  , f = require(&#39;util&#39;).format;

// Keep the original findOne method
var findOne = Collection.prototype.findOne;
// Create our own overriding findOne method that wraps the original
Collection.prototype.findOne = function() {
  var startTime = new Date().getTime();
  // Get all the passed in arguments as an array
  var args = Array.prototype.slice.call(arguments, 0);
  // Get the callback at the end of the function
  var callback = args.pop();
  // Push our own callback handler that calls the original 
  // callback after finishing up it&#39;s goals
  args.push(function(err, r) {
    var endTime = new Date().getTime();
    console.log(f(&amp;quot;findOne took %s milliseconds&amp;quot;, (endTime - startTime)))
    callback(err, r)
  });

  // Call the original prototype method findOne on this instance
  return findOne.apply(this, args);
}

MongoClient.connect(&#39;mongodb://localhost:27017/test&#39;, function(err, db) {
  db.collection(&#39;t&#39;).findOne({}, function(err, r) {
    db.close();
  });
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this code we change the behavior of the findOne method by wrapping it in our own method that records the start and end times of the findOne operation and prints the number of milliseconds it took to the console. The cool thing is that this is global. Once we changed &lt;code&gt;Collection.prototype&lt;/code&gt; we automatically get our new wrapped method for all methods that create a new &lt;code&gt;Collection&lt;/code&gt; instance allowing us to instruments all calls using &lt;code&gt;Collection.findOne&lt;/code&gt; across our application.&lt;/p&gt;

&lt;p&gt;There is not much more to it so go ahead and think of some crazy ways to use this and if you do something very clever let me know :).&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>